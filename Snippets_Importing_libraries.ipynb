{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nama-pooja/shadowfox/blob/main/Snippets_Importing_libraries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDn_lVxg3Z2G"
      },
      "source": [
        "# Importing a library that is not in Colaboratory\n",
        "\n",
        "To import a library that's not in Colaboratory by default, you can use `!pip install` or `!apt-get install`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ18Kd5F3uKe",
        "outputId": "cf89aa45-fbd2-491d-e956-880d9999eca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib-venn"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xYZhLdwfBYV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__3eqm3q3sr-",
        "outputId": "122e1a2c-c0ed-432b-cf8b-95730cd2ed25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Package 'libfluidsynth1' has no installation candidate\n"
          ]
        }
      ],
      "source": [
        "!apt-get -qq install -y libfluidsynth1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apoRbfWsRZ7S"
      },
      "source": [
        "# Install 7zip reader [libarchive](https://pypi.python.org/pypi/libarchive)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeaSX9KXR58J"
      },
      "source": [
        "# Install GraphViz & [PyDot](https://pypi.python.org/pypi/pydot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9llCG2wSRDx",
        "outputId": "3db5af47-e34c-434e-eb2b-e1a22fae11a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tlh1MKxGrKFO"
      },
      "source": [
        "# Install [cartopy](http://scitools.org.uk/cartopy/docs/latest/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq68DSY2rP2W",
        "outputId": "5d395b2f-a3b7-476b-cbf1-ba3d7cfad009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cartopy\n",
            "  Downloading Cartopy-0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from cartopy) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.8.0)\n",
            "Requirement already satisfied: shapely>=1.8 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.0.6)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from cartopy) (24.2)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->cartopy) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=3.3.1->cartopy) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->cartopy) (1.16.0)\n",
            "Downloading Cartopy-0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cartopy\n",
            "Successfully installed cartopy-0.24.1\n"
          ]
        }
      ],
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf # Import the tensorflow library and alias it as 'tf'\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() # Use 'tf.keras' to access the 'keras' module\n"
      ],
      "metadata": {
        "id": "9GSzZudFBm6m",
        "outputId": "ba9cb436-308e-4101-ff1b-0382efcdb246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: #Normalize pixel values to [0, 1]\n",
        "# x_train = x_train.astype('float32') / 255\n",
        "# x_test = x_test.astype('float32') / 255\n",
        "\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "metadata": {
        "id": "Y5HS3wtuB9Kg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: y_train = keras.utils.to_categorical(y_train, 10)\n",
        "# y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "id": "Je4I7OKCCUcx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "FxoC94gMCuG3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Define data generators for training and validation\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rotation_range=15,\n",
        "#     width_shift_range=0.1,\n",
        "#     height_shift_range=0.1,\n",
        "#     horizontal_flip=True,\n",
        "# )\n",
        "# val_datagen = ImageDataGenerator()\n",
        "# train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n",
        "# val_generator = val_datagen.flow(x_val, y_val, batch_size=32)\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define data generators for training and validation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "val_datagen = ImageDataGenerator()\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n",
        "val_generator = val_datagen.flow(x_val, y_val, batch_size=32)"
      ],
      "metadata": {
        "id": "40BNtPcTDDR_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: model = keras.models.Sequential([\n",
        "#     keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "#     keras.layers.MaxPooling2D((2, 2)),\n",
        "#     keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "#     keras.layers.MaxPooling2D((2, 2)),\n",
        "#     keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "#     keras.layers.Flatten(),\n",
        "#     keras.layers.Dense(128, activation='relu'),\n",
        "#     keras.layers.Dropout(0.2),\n",
        "#     keras.layers.Dense(10, activation='softmax')\n",
        "# ])\n",
        "\n",
        "import tensorflow as tf # Import the tensorflow library and alias it as 'tf'\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data() # Use 'tf.keras' to access the 'keras' module\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Define data generators for training and validation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "val_datagen = ImageDataGenerator()\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n",
        "val_generator = val_datagen.flow(x_val, y_val, batch_size=32)"
      ],
      "metadata": {
        "id": "CXa2klYLDV8t",
        "outputId": "61d5d213-4650-406e-ffa5-f0baf0c99c8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: model.compile(optimizer='adam',\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_generator,\n",
        "          epochs=10,  # You might want to increase the number of epochs\n",
        "          validation_data=val_generator)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "4A76hoC4EHOZ",
        "outputId": "0cb49c74-017b-45b2-a0ad-9f505fb8866d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 78ms/step - accuracy: 0.3078 - loss: 1.8497 - val_accuracy: 0.5298 - val_loss: 1.3077\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 76ms/step - accuracy: 0.4939 - loss: 1.4016 - val_accuracy: 0.5896 - val_loss: 1.1576\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 76ms/step - accuracy: 0.5529 - loss: 1.2549 - val_accuracy: 0.6191 - val_loss: 1.0641\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.5886 - loss: 1.1678 - val_accuracy: 0.6647 - val_loss: 0.9500\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 77ms/step - accuracy: 0.6127 - loss: 1.1052 - val_accuracy: 0.6757 - val_loss: 0.9261\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 75ms/step - accuracy: 0.6340 - loss: 1.0430 - val_accuracy: 0.6766 - val_loss: 0.9117\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 77ms/step - accuracy: 0.6531 - loss: 0.9984 - val_accuracy: 0.7020 - val_loss: 0.8460\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.6588 - loss: 0.9767 - val_accuracy: 0.7014 - val_loss: 0.8791\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 76ms/step - accuracy: 0.6720 - loss: 0.9395 - val_accuracy: 0.6985 - val_loss: 0.9007\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.6784 - loss: 0.9247 - val_accuracy: 0.7015 - val_loss: 0.8537\n",
            "313/313 - 4s - 14ms/step - accuracy: 0.7047 - loss: 0.8523\n",
            "\n",
            "Test accuracy: 0.7046999931335449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Train the model\n",
        "# history = model.fit(train_generator, epochs=10, validation_data=val_generator)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=10, validation_data=val_generator)"
      ],
      "metadata": {
        "id": "6wKWjqu8Iwcg",
        "outputId": "d6b7b0c8-7a0a-4b37-cf7a-22c15fdd40b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.6840 - loss: 0.8969 - val_accuracy: 0.7288 - val_loss: 0.7816\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 76ms/step - accuracy: 0.6902 - loss: 0.8893 - val_accuracy: 0.7178 - val_loss: 0.8284\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 76ms/step - accuracy: 0.6930 - loss: 0.8893 - val_accuracy: 0.7333 - val_loss: 0.7703\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 74ms/step - accuracy: 0.7049 - loss: 0.8496 - val_accuracy: 0.7325 - val_loss: 0.7755\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 75ms/step - accuracy: 0.7024 - loss: 0.8433 - val_accuracy: 0.7369 - val_loss: 0.7552\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.7083 - loss: 0.8309 - val_accuracy: 0.7225 - val_loss: 0.8051\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.7100 - loss: 0.8257 - val_accuracy: 0.7400 - val_loss: 0.7597\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 75ms/step - accuracy: 0.7130 - loss: 0.8159 - val_accuracy: 0.7384 - val_loss: 0.7714\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 76ms/step - accuracy: 0.7208 - loss: 0.8005 - val_accuracy: 0.7413 - val_loss: 0.7437\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 74ms/step - accuracy: 0.7195 - loss: 0.8020 - val_accuracy: 0.7391 - val_loss: 0.7713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Evaluate the model\n",
        "# test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "# print(f'Test accuracy: {test_acc:.2f}')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "cEuTODpxN3bX",
        "outputId": "05aa0a9c-680f-4d92-9e19-a4d6d1007dcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 4s - 12ms/step - accuracy: 0.7371 - loss: 0.7748\n",
            "\n",
            "Test accuracy: 0.7371000051498413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt:  #Save the model\n",
        "# model.save('image_tagging_model.h5')\n",
        "\n",
        "#Save the model\n",
        "model.save('image_tagging_model.h5')"
      ],
      "metadata": {
        "id": "dN-fxI4SODY8",
        "outputId": "028445b3-e4a9-4ad8-c5aa-fbb25f7da6eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Define function for image tagging\n",
        "# def tag_image(image_path):\n",
        "#     img = keras.preprocessing.image.load_img(image_path, target_size=(32, 32))\n",
        "#     img_array = keras.preprocessing.image.img_to_array(img)\n",
        "#     img_array = tf.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def tag_image(image_path):\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=(32, 32))\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, axis=0) / 255.0\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    # You'll need a way to map the predicted_class index to an actual tag.\n",
        "    # For now, we'll just return the index.\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "CKR2HmpCOPTa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt:  predictions = model.predict(img_array)\n",
        "#     predicted_class = tf.argmax(predictions, axis=1)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def tag_image(image_path):\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=(32, 32))\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, axis=0) / 255.0\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    # You'll need a way to map the predicted_class index to an actual tag.\n",
        "    # For now, we'll just return the index.\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "qdpP0pflO4gP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: #Map predicted class to label\n",
        "#     labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "#     predicted_label = labels[predicted_class.numpy()[0]]\n",
        "#     return predicted_label\n",
        "\n",
        "def tag_image(image_path):\n",
        "    img = keras.preprocessing.image.load_img(image_path, target_size=(32, 32))\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, axis=0) / 255.0\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = np.argmax(predictions[0])\n",
        "    labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    predicted_label = labels[predicted_class.numpy()[0]]\n",
        "    return predicted_label"
      ],
      "metadata": {
        "id": "oaXbjL8_PEJA"
      },
      "execution_count": 23,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Snippets: Importing libraries",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}